{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refining chunk 1 of 8...\n",
      "Refining chunk 2 of 8...\n",
      "Refining chunk 3 of 8...\n",
      "Refining chunk 4 of 8...\n",
      "Refining chunk 5 of 8...\n",
      "Refining chunk 6 of 8...\n",
      "Refining chunk 7 of 8...\n",
      "Refining chunk 8 of 8...\n",
      "Refined transcript saved to D:/EducareAI/first_task/refined_text/4th_Grade_Science_binary_refined.txt\n",
      "Analyzing chunk 1 of 5...\n",
      "An error occurred while converting to Excel: Response does not contain both student and teacher tables.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# openai.api_key = \"your-openai-api-key\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def refine_transcript_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Refines a single chunk of the transcript using OpenAI API.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with refining a portion of a classroom audio transcription to make it coherent, structured, and accurate.\n",
    "    Follow these rules:\n",
    "    1. Consolidate the speech of the same speaker into cohesive blocks while preserving logical flow and context.\n",
    "    2. Clearly differentiate between teacher and students based on the following:\n",
    "        - The teacher addresses students by their names when asking questions.\n",
    "        - Assume the reply immediately following a question is by the addressed student, unless explicitly attributed otherwise.\n",
    "        - If the teacher uses ambiguous terms (e.g., \"um,\" \"Em,\" \"uh,\" or similar), recognize these as filler words unless clearly referring to a student.\n",
    "    3. Unless explicitly addressed, assume the speaker is the teacher.\n",
    "    4. Retain timestamps where available and align them with the refined text.\n",
    "    5. Organize the transcript clearly with \"Teacher\" and \"Student <Name>\" labels, ensuring the flow of dialogue makes sense.\n",
    "    6. Eliminate filler words like \"um,\" \"uh,\" or other pauses, unless critical to the dialogue or context.\n",
    "    7. Improve grammar, punctuation, and formatting for clarity and professionalism.\n",
    "\n",
    "    Here is a portion of the original transcript:\n",
    "    {chunk}\n",
    "\n",
    "    Now provide the fully refined and improved portion:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a skilled text refinement assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=2000,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while refining a chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_transcript(transcript, max_tokens=3000):\n",
    "    \"\"\"\n",
    "    Splits the transcript into smaller chunks that fit within the token limit.\n",
    "    \"\"\"\n",
    "    words = transcript.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(\" \".join(current_chunk)) > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def refine_classroom_transcript(input_path, refined_path):\n",
    "    \"\"\"\n",
    "    Refines a long classroom transcript by splitting it into smaller chunks and saving the refined output.\n",
    "    \"\"\"\n",
    "    with open(input_path, \"r\") as file:\n",
    "        transcript = file.read()\n",
    "\n",
    "    chunks = split_transcript(transcript)\n",
    "\n",
    "    refined_transcript = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Refining chunk {i + 1} of {len(chunks)}...\")\n",
    "        refined_chunk = refine_transcript_chunk(chunk)\n",
    "        if refined_chunk:\n",
    "            refined_transcript.append(refined_chunk)\n",
    "        else:\n",
    "            print(f\"Skipping chunk {i + 1} due to an error.\")\n",
    "\n",
    "    with open(refined_path, \"w\") as file:\n",
    "        file.write(\"\\n\\n\".join(refined_transcript))\n",
    "    \n",
    "    print(f\"Refined transcript saved to {refined_path}\")\n",
    "\n",
    "def split_for_analysis(transcript, max_tokens=4000):\n",
    "    \"\"\"\n",
    "    Splits the refined transcript into smaller chunks for analysis.\n",
    "\n",
    "    Args:\n",
    "    - transcript (str): The refined transcript.\n",
    "    - max_tokens (int): Maximum token limit for each chunk.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of transcript chunks.\n",
    "    \"\"\"\n",
    "    words = transcript.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(\" \".join(current_chunk)) > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def analyze_transcript(file_path):\n",
    "    \"\"\"\n",
    "    Analyze the classroom transcript and generate structured data for students and teachers.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the transcript text file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Generated structured data from OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the transcript from the text file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            transcript = file.read()\n",
    "        # Split refined transcript into chunks\n",
    "        chunks = split_for_analysis(transcript)\n",
    "        # Analyze each chunk\n",
    "        combined_results = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"Analyzing chunk {i + 1} of {len(chunks)}...\")\n",
    "            # Define the prompt\n",
    "            prompt = f\"\"\"\n",
    "            You are tasked with analyzing the classroom transcript provided below to generate detailed and specific learnings and improvements for both students and teachers.\n",
    "\n",
    "            Here is the transcript:\n",
    "            {chunk}\n",
    "\n",
    "            Instructions:\n",
    "            1. Analyze the transcript and identify positive learnings done by students, mentioning their names and ensure you correctly identify when a student is speaking versus when the teacher is speaking.\n",
    "            - Use context to differentiate random words or filler terms from actual student names.\n",
    "            - Only consider a word to be a student name if the teacher directly addresses the person (e.g., \"Adrian, can you tell me...\") or if it is clearly followed by a student's response.\n",
    "            2. Highlight improvements needed for students based on their participation or responses.\n",
    "            3. For teachers:\n",
    "            - Capture specific positive enhancements (e.g., teaching methods, interactions).\n",
    "            - Mention improvements needed in their teaching style or interactions.\n",
    "            4. Output two separate tables:\n",
    "            - One for students with columns: \"Date\", \"Student Name\", \"Positive Learnings\", \"Improvements Needed\".\n",
    "            - One for teachers with columns: \"Date\", \"Teacher Name\", \"Positive Enhancements\", \"Improvements Needed\".\n",
    "            5. Analyze the transcript carefully:\n",
    "            - Identify positive learnings done by students based on their participation or responses, mentioning their names.\n",
    "            - Highlight improvements needed for students if their responses are incomplete or they were not engaged.\n",
    "            - Capture specific positive enhancements for teachers (e.g., encouraging participation, providing examples).\n",
    "            - Highlight improvements needed for teachers (e.g., managing pacing, giving clearer instructions).\n",
    "            6. Assume today's date for all records and generate realistic and specific data.\n",
    "            7. Ensure that:\n",
    "            - \"Student Name\" is populated only when it is explicitly mentioned in the transcript or contextually clear.\n",
    "            - Generic filler words like \"Em\" or random phrases are not misinterpreted as names.\n",
    "            - The output is realistic and specific.\n",
    "\n",
    "            Provide the data in a structured format with the following tables:\n",
    "            - Table 1: Students\n",
    "            - Table 2: Teachers\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # Call OpenAI API\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a skilled data analysis assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=2000,\n",
    "                )\n",
    "                combined_results.append(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing chunk {i + 1}: {e}\")\n",
    "            \n",
    "            return \"\\n\\n\".join(combined_results)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path {file_path}. Please provide a valid file path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_openai_response_to_excel(response, student_file, teacher_file):\n",
    "    \"\"\"\n",
    "    Converts OpenAI response into two Excel files for students and teachers.\n",
    "\n",
    "    Args:\n",
    "    - response (str): The OpenAI response containing structured tables.\n",
    "    - student_file (str): Path to save the Excel file for student data.\n",
    "    - teacher_file (str): Path to save the Excel file for teacher data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate \"Table 1: Students\" and \"Table 2: Teachers\"\n",
    "        student_start = response.find(\"Table 1: Students\")\n",
    "        teacher_start = response.find(\"Table 2: Teachers\")\n",
    "\n",
    "        if student_start == -1:\n",
    "            print(\"Warning: 'Table 1: Students' not found in the response.\")\n",
    "            student_section = None\n",
    "        else:\n",
    "            student_section = response[student_start:teacher_start if teacher_start != -1 else len(response)].strip()\n",
    "\n",
    "        if teacher_start == -1:\n",
    "            print(\"Warning: 'Table 2: Teachers' not found in the response.\")\n",
    "            teacher_section = None\n",
    "        else:\n",
    "            teacher_section = response[teacher_start:].strip()\n",
    "\n",
    "        # Process student data\n",
    "        if student_section:\n",
    "            student_lines = student_section.split(\"\\n\")\n",
    "            student_columns = student_lines[2].strip(\"|\").split(\"|\")  # Extract column headers\n",
    "            student_columns = [col.strip() for col in student_columns if col.strip()]\n",
    "            student_rows = [\n",
    "                [field.strip() for field in line.strip(\"|\").split(\"|\")]\n",
    "                for line in student_lines[4:] if line.strip() and \"|\" in line\n",
    "            ]\n",
    "            student_df = pd.DataFrame(student_rows, columns=student_columns)\n",
    "        else:\n",
    "            print(\"Warning: No student data found in the response.\")\n",
    "            student_df = pd.DataFrame(columns=[\"Date\", \"Student Name\", \"Positive Learnings\", \"Improvements Needed\"])\n",
    "\n",
    "        # Process teacher data\n",
    "        if teacher_section:\n",
    "            teacher_lines = teacher_section.split(\"\\n\")\n",
    "            teacher_columns = teacher_lines[2].strip(\"|\").split(\"|\")  # Extract column headers\n",
    "            teacher_columns = [col.strip() for col in teacher_columns if col.strip()]\n",
    "            teacher_rows = [\n",
    "                [field.strip() for field in line.strip(\"|\").split(\"|\")]\n",
    "                for line in teacher_lines[4:] if line.strip() and \"|\" in line\n",
    "            ]\n",
    "            teacher_df = pd.DataFrame(teacher_rows, columns=teacher_columns)\n",
    "        else:\n",
    "            print(\"Warning: No teacher data found in the response.\")\n",
    "            teacher_df = pd.DataFrame(columns=[\"Date\", \"Teacher Name\", \"Positive Enhancements\", \"Improvements Needed\"])\n",
    "\n",
    "        # Save to Excel files\n",
    "        student_df.to_excel(student_file, index=False)\n",
    "        teacher_df.to_excel(teacher_file, index=False)\n",
    "\n",
    "        print(f\"Excel files created:\\n- Students: {student_file}\\n- Teachers: {teacher_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while converting to Excel: {e}\")\n",
    "\n",
    "\n",
    "def automate_pipeline(input_path, refined_path, student_file, teacher_file):\n",
    "    \"\"\"\n",
    "    Automates the pipeline: refining transcript, analyzing it, and saving results to Excel.\n",
    "    \"\"\"\n",
    "    refine_classroom_transcript(input_path, refined_path)\n",
    "    generated_data = analyze_transcript(refined_path)\n",
    "    if generated_data:\n",
    "        convert_openai_response_to_excel(generated_data, student_file, teacher_file)\n",
    "    else:\n",
    "        print(\"Analysis failed. No Excel files generated.\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"D:/EducareAI/first_task/4th_Grade_Science_binary.txt\"\n",
    "refined_file = \"D:/EducareAI/first_task/refined_text/4th_Grade_Science_binary_refined.txt\"\n",
    "student_excel = \"D:/EducareAI/first_task/analysis/4th_Grade/students_analysis.xlsx\"\n",
    "teacher_excel = \"D:/EducareAI/first_task/analysis/4th_Grade/teachers_analysis.xlsx\"\n",
    "\n",
    "automate_pipeline(input_file, refined_file, student_excel, teacher_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing chunk 1 of 5...\n",
      "Table 1: Students\n",
      "\n",
      "| Date | Student Name | Positive Learnings | Improvements Needed |\n",
      "|------|--------------|--------------------|---------------------|\n",
      "| Today's Date | Unidentified Student | Identified features of an insect and applied this knowledge to assert that a cricket is an insect | Could work on being more confident when sharing their thoughts |\n",
      "| Today's Date | Isabel | Participated actively in the discussion and was able to share her thoughts | Need to improve on the understanding of insect anatomy, specifically the number of legs |\n",
      "| Today's Date | Unidentified Student | Disagreed respectfully with Isabel and correctly identified the number of cricket's legs | Can work on providing a more detailed explanation to support their argument |\n",
      "| Today's Date | Skylar | Confirmed that a cricket is an insect by observing and discussing with a partner | Could improve by providing more reasoning or facts to support their argument |\n",
      "| Today's Date | Unidentified Student | Showed interest and enthusiasm in observing the cricket | Need to focus on the task at hand and avoid distractions |\n",
      "\n",
      "Table 2: Teachers\n",
      "\n",
      "| Date | Teacher Name | Positive Enhancements | Improvements Needed |\n",
      "|------|--------------|-----------------------|---------------------|\n",
      "| Today's Date | Unidentified Teacher | Encouraged active participation, provided hands-on learning experience, and facilitated group discussions | Could work on giving clearer instructions. For example, the instructions for the drawing activity could have been more concise |\n",
      "| Today's Date | Unidentified Teacher | Praised students for their participation and correct answers, guided students in their drawing activity | Could improve on pacing, allowing students enough time to think and respond |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_data = analyze_transcript(refined_file)\n",
    "print(generated_data)\n",
    "# if generated_data:\n",
    "#         convert_openai_response_to_excel(generated_data, student_excel, teacher_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel files created:\n",
      "- Students: D:/EducareAI/first_task/analysis/4th_Grade/students_analysis.xlsx\n",
      "- Teachers: D:/EducareAI/first_task/analysis/4th_Grade/teachers_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if generated_data:\n",
    "        convert_openai_response_to_excel_1(generated_data, student_excel, teacher_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "educare_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
